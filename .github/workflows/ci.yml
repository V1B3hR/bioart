name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      run_benchmarks:
        description: 'Run full benchmark suite'
        required: false
        default: 'false'
        type: boolean
  schedule:
    # Weekly run on Sundays at 2 AM UTC to catch latent issues
    - cron: '0 2 * * 0'

# Explicit permissions (least-privilege)
permissions:
  contents: read
  actions: read
  checks: write

# Concurrency group to avoid overlapping runs for same ref
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHONUNBUFFERED: 1
  COVERAGE_CORE: sysmon

jobs:
  lint:
    name: Code Quality & Linting
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11 for linting
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: |
            requirements.txt
            dev-requirements.txt

      - name: Install linting dependencies
        run: |
          python -m pip install --upgrade pip
          pip install flake8

      - name: Run flake8 critical error checks
        run: |
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics

      - name: Run flake8 advisory checks
        run: |
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

  test:
    name: Test Suite (Python ${{ matrix.python-version }})
    runs-on: ubuntu-24.04
    needs: lint
    strategy:
      fail-fast: false
      matrix:
        python-version: [ "3.8", "3.9", "3.10", "3.11" ]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: pip
          cache-dependency-path: |
            requirements.txt
            dev-requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          
          # Install main requirements if present
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          
          # Install dev requirements if present
          if [ -f dev-requirements.txt ]; then
            pip install -r dev-requirements.txt
          fi
          
          # Install testing dependencies
          pip install pytest coverage pytest-cov

      - name: Create test results directory
        run: |
          mkdir -p tests/junit

      - name: Run unified test discovery with pytest (if tests/ exists)
        if: hashFiles('tests/test_*.py') != ''
        run: |
          # Run pytest with coverage and JUnit XML output
          python -m pytest tests/ \
            --cov=src \
            --cov-report=xml:coverage.xml \
            --cov-report=html:htmlcov \
            --cov-report=term-missing \
            --junitxml=tests/junit/test-results.xml \
            -v
          
          # Fail if no tests were collected when tests/ directory exists
          if [ $(python -m pytest tests/ --collect-only -q | grep -c "collected") -eq 0 ]; then
            echo "Error: No tests collected from tests/ directory"
            exit 1
          fi

      - name: Display coverage summary in logs
        if: hashFiles('tests/test_*.py') != '' && hashFiles('coverage.xml') != ''
        run: |
          echo "=== Coverage Summary ==="
          python -m coverage report --show-missing

      - name: Run legacy core tests (if present)
        if: hashFiles('run_tests.py') != ''
        run: |
          python run_tests.py

      - name: Run legacy repository tests (if present)
        if: hashFiles('test_repo.py') != ''
        run: |
          python test_repo.py

      - name: Run legacy advanced tests (if present)
        if: hashFiles('tests/advanced_tests.py') != ''
        run: |
          python tests/advanced_tests.py

      - name: Run legacy enhanced features tests (if present)
        if: hashFiles('tests/test_enhanced_features.py') != ''
        run: |
          python tests/test_enhanced_features.py

      - name: Run legacy AI PoC validation tests (if present)
        if: hashFiles('tests/test_ai_poc_validation.py') != ''
        run: |
          python tests/test_ai_poc_validation.py

      - name: Run legacy stress tests (if present)
        if: hashFiles('tests/stress_tests.py') != ''
        run: |
          python tests/stress_tests.py

      - name: Run quick benchmark suite (if present)
        if: hashFiles('benchmarks/benchmark_suite.py') != ''
        run: |
          # Quick mode (adjust flag as needed)
          python benchmarks/benchmark_suite.py --ci || echo "Benchmarks (quick) completed with non-zero exit (tolerated)."

      - name: List installed packages on test failure
        if: failure()
        run: |
          echo "=== Installed Python packages ==="
          pip freeze

      - name: Upload test results and coverage artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-py${{ matrix.python-version }}
          path: |
            tests/junit/test-results.xml
            coverage.xml
            htmlcov/
            benchmarks/results/
            tests/artifacts/
          if-no-files-found: ignore

  benchmark:
    name: Performance Benchmarks (Full Suite)
    runs-on: ubuntu-24.04
    needs: test
    # Run on push to main/develop, manual dispatch, or scheduled runs
    if: |
      (github.event_name == 'push' && contains(fromJSON('["main", "develop"]'), github.ref_name)) ||
      (github.event_name == 'workflow_dispatch' && inputs.run_benchmarks == 'true') ||
      github.event_name == 'schedule'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11 for benchmarks
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: |
            requirements.txt
            dev-requirements.txt

      - name: Install benchmark dependencies
        run: |
          python -m pip install --upgrade pip
          
          # Install main requirements if present
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          
          # Install dev requirements if present for benchmarks
          if [ -f dev-requirements.txt ]; then
            pip install -r dev-requirements.txt
          fi

      - name: Run comprehensive performance benchmarks
        if: hashFiles('benchmarks/benchmark_suite.py') != ''
        run: |
          python benchmarks/benchmark_suite.py --ci --full || echo "Full benchmarks completed with non-zero exit (tolerated)."

      - name: Upload comprehensive benchmark results
        if: always() && hashFiles('benchmarks/results/**') != ''
        uses: actions/upload-artifact@v4
        with:
          name: full-benchmark-results
          path: benchmarks/results/
          if-no-files-found: ignore